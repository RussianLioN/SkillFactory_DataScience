# Проект 1. Анализ вакансий на hh.ru

## Оглавление
[1. Описание проекта](#описание-проекта)  
[2. Какой кейс решаем?](#какой-кейс-решаем)  
[3. Краткая информация о данных](#краткая-информация-о-данных)  
[4. Этапы работы над проектом](#этапы-работы-над-проектом)  
[5. Результат](#результаты)    
[6. Выводы](#выводы) 

### Описание проекта    
Проект по обработке и анализу файла данных с резюме компании HeadHunter

⤒ [к оглавлению](#оглавление)


### Какой кейс решаем?    
В проекте необходимо выполнить следующие задачи:
- базовый анализ структуры данных;
- преобразование данных;
- разведывательный анализ;
- очистка данных

**Условия заадачи:**  
Компания HeadHunter хочет построить модель, которая бы автоматически определяла примерный уровень заработной платы, подходящей пользователю, исходя из информации, которую он указал о себе. Но, прежде чем построить модель, *данные необходимо преобразовать, исследовать и очистить*. В этом и состоит наша с вами задача!

**Метрика качества**     
Сдать проект на проверку ментору и получить 10 баллов (из них 8 баллов — за основное задание и 2 балла — за дополнительное) за выводы по разведывательному анализу.

**Что практикуем**     
Пробуем свои силы в реальном Data Science-проекте. Будем решить часть настоящей бизнес-задачи и примерить роль аналитика в компании HeadHunter. Проект дожен стать новым этапом сбора моего портфолио на GitHub, который я смогу презентовать потенциальному работодателю!


### Краткая информация о данных
Для работы кода используются модули:

    pandas
    numpy
    matplotlib.pyplot
    seaborn
    plotly

файлы данных:

- [dst-3.0_16_1_hh_database.csv](https://disk.yandex.ru/d/gRrbNWCL-wjtQw "Исходный файл резюме")
- ExchangeRates.csv

ноутбук-шаблон

    Ноутбук-шаблон Project 1.ipynb

а также основной файл ноутбука:

    Project1.ipynb
в котором производится вызов всех модулей(файлов) проекта и выводится результат со средним количеством попыток угадываний для каждого метода
  
⤒ [к оглавлению](#оглавление)


### Этапы работы над проектом

1. *Исследована структура данных*.

Разобрались, как устроены признаки в данных и какие типы они имеют, чтобы произвести дальнейшие преобразования.

2. *Преобразованы данные* 

Выполнена предобработка данных с помощью функций-преобразований (lambda-функций), которые принимают аргументом элемент столбца и возвращают его преобразованную версию.

3. *Исследована зависимость в данных*

Провели первичный анализ зависимостей в наших данных о резюме - разведывательный анализ (EDA)

4. *Проведена очистка данных*

⤒ [к оглавлению](#оглавление)


### Результаты:  
Успешно завершен первый data science проект! Испытали на себе основные этапы работы с данными на примере датасета о вакансиях и научились правильно работать с данными.

⤒ [к оглавлению](#оглавление)


### Выводы:  

Любые исходные данные требуют основательной обработки, анализа и очистки, чтобы их можно было применять для даальнейшей работы, например для построения моделей. Поэтому, считаю этот этап одним из самых важных и ответственных!

⤒ [к оглавлению](#оглавление)


Если информация по этому проекту покажется вам интересной или полезной, то я буду очень вам благодарен, если отметите репозиторий и профиль ⭐️⭐️⭐️-дами  